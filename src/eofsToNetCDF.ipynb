{
 "metadata": {
  "name": "",
  "signature": "sha256:f71cecd6d55a07dedb1c726ca653159f903a384a6aae1bbc551d9f7edc3e8228"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " Assuming EOFs have been converted from Binary to CSV format, converts them to netCDF CDL specification \n",
      " to be compiled to netCDF using ncgen. Note: this was necessary because it's not clear to me how to use PyNetCDF to directly\n",
      " generate a netcdf file with the structure I want. Once the CDL file has been compiled to NetCDF, one could maybe load this back in and look at its structure to determine how to create it directly... "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark import SparkContext\n",
      "import pygrib\n",
      "import numpy as np\n",
      "from boto.s3.connection import S3Connection\n",
      "import subprocess, time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Download a generic grib2 file from S3 to load the latitude, longtitude, and observation mask information. requires the AWS_KEY and AWS_SECRET_KEY environment variables be set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gribtemplatefname = '/home/ubuntu/large-scale-climate/data/template.grb2'\n",
      "aws_key = os.environ.get('AWS_KEY')\n",
      "aws_secret_key = os.environ.get('AWS_SECRET_KEY')\n",
      "conn = S3Connection(aws_key, aws_secret_key)\n",
      "aws_key = None # So aren't saved in notebook (not sure they would be, but lets be safe)\n",
      "aws_secret_key = None\n",
      "\n",
      "with open(gribtemplatefname, 'w') as fout:\n",
      "    conn.get_bucket('agittens').get_key('CSFR-O/grib2/ocnh06.gdas.1979010100.grb2').get_file(fout)\n",
      "grbs = pygrib.open(gribtemplatefname)\n",
      "lats, lons = grbs[207].latlons()\n",
      "lats = lats[:, 0]\n",
      "lons = lons[0, :]\n",
      "\n",
      "gribindices = range(1,41)\n",
      "gribindices.append(207)\n",
      "gribindices = list(reversed(gribindices))\n",
      "\n",
      "dimsperlevel = 360*720\n",
      "dims = dimsperlevel * 41\n",
      "mask = np.zeros((dims,)) < 0\n",
      "\n",
      "for index in range(41):\n",
      "    mask[index*dimsperlevel:(index+1)*dimsperlevel] = grbs[gribindices[index]].data()[0].mask.reshape((dimsperlevel,))\n",
      "    \n",
      "# hard-coded (got out of ncdump of a netcdf file from the CFSR, compared to grbs for correctness)\n",
      "# alternatively, use something like\n",
      "#for idx in gribindices:\n",
      "#   m = re.search('(?<=level )\\d+', str(grbs[idx]))\n",
      "#   print m.group(0)\n",
      "\n",
      "levels = np.array([0, 5, 15, 25, 35, 45, 55, 65, 75, 85, 95, 105, 115, 125, 135, \\\n",
      "                   145, 155, 165, 175, 185, 195, 205, 215, 225, 238, 262, 303, \\\n",
      "                   366, 459, 584, 747, 949, 1193, 1479, 1807, 2174, 2579, 3016, \\\n",
      "                   3483, 3972, 4478])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load the EOF and col-to-date mapping information from CSV"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def loadEOF(fname, numeofs, numobs):\n",
      "    eofs = np.zeros((numeofs, numobs))\n",
      "    with open(fname, 'r') as fin:\n",
      "        fin.readline() # skip the two header lines\n",
      "        fin.readline()\n",
      "        for line in fin:\n",
      "            (i, j, v) = line.split()\n",
      "            eofs[int(j)-1, int(i)-1] = float(v)\n",
      "    return eofs\n",
      "\n",
      "def loadVec(fname, numeofs):\n",
      "    vec = np.zeros((numeofs,))\n",
      "    with open(fname, 'r') as fin:\n",
      "        fin.readline()\n",
      "        fin.readline()\n",
      "        for line in fin:\n",
      "            (i,j,v) = line.split()\n",
      "            vec[int(j)-1] = float(v)\n",
      "    return vec\n",
      "\n",
      "def fullEOF(eof):\n",
      "    eofpadded = 9999*np.ones((dims,))\n",
      "    eofpadded[mask == False] = eof\n",
      "    return eofpadded\n",
      "\n",
      "csvtodatestr = {}\n",
      "with open(\"/home/ubuntu/large-scale-climate/data/csvrow-to-gribdate-mapping\") as fin:\n",
      "    for line in fin:\n",
      "        (csvrow, datestr) = line.split(',')\n",
      "        csvtodatestr[int(csvrow)] = datestr.rstrip()\n",
      "        \n",
      "parquetcols = []\n",
      "with open(\"/home/ubuntu/large-scale-climate/data/parquetcol-to-csvrow-mapping\") as fin:\n",
      "    for line in fin:\n",
      "        parquetcols.append(int(line.rstrip()))\n",
      "        \n",
      "skippedcols = [idx for idx in csvtodatestr.keys() if idx not in parquetcols]\n",
      "skippeddates = [csvtodatestr[colidx] for colidx in skippedcols]\n",
      "assert(len(skippeddates) + len(parquetcols) == len(csvtodatestr))\n",
      "\n",
      "coldates = [None] * len(parquetcols)\n",
      "for colidx in range(len(parquetcols)):\n",
      "    coldates[colidx] = csvtodatestr[parquetcols[colidx]]\n",
      "    \n",
      "observedeofs = loadEOF(\"/home/ubuntu/large-scale-climate/data/colEOFs\", 20, 6349676)\n",
      "singvals = loadVec(\"/home/ubuntu/large-scale-climate/data/evalEOFs\", 20)\n",
      "observedmeans = loadVec(\"/home/ubuntu/large-scale-climate/data/rowMeans\", 6349676)\n",
      "temporaleofs = loadEOF(\"/home/ubuntu/large-scale-climate/data/rowEOFs\", 20, 46715)\n",
      "\n",
      "spatialeofs = np.zeros((20, dims))\n",
      "for idx in range(20):\n",
      "    spatialeofs[idx, :] = fullEOF(observedeofs[idx, :])\n",
      "means = fullEOF(observedmeans)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write out the CDL file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import time\n",
      "\n",
      "eofs_ncdump_template_header = \\\n",
      "\"\"\"\n",
      "netcdf {0} {{\n",
      "    //CDL specification for EOF file, cf https://www.unidata.ucar.edu/software/netcdf/docs/ncgen-man-1.html for format specification\n",
      "    \n",
      "    dimensions:\n",
      "        lat_0 = 360 ;\n",
      "        lon_0 = 720 ;\n",
      "        lv_DBSL0 = 41 ;\n",
      "        numeofs = {1} ;\n",
      "        numdates = {2} ;\n",
      "        lengthofdate = 10;\n",
      "        \n",
      "    variables:\n",
      "        float lat_0(lat_0) ;\n",
      "        float lon_0(lon_0) ;\n",
      "        float lv_DBSL0(lv_DBSL0) ;\n",
      "        float singvals(numeofs) ;\n",
      "        \n",
      "        float temporalEOFs(numeofs, numdates) ;\n",
      "        char coldates(numdates, lengthofdate) ;\n",
      "        \n",
      "        float meanTemps(lv_DBSL0, lat_0, lon_0) ;\n",
      "{3}\n",
      "        :creation_date = \"{4}\" ;\n",
      "        :Conventions = \"None\" ;\n",
      "    \n",
      "    data:\n",
      "\"\"\"\n",
      "\n",
      "spatial_eof_variable_specification_template = \\\n",
      "\"\"\"\n",
      "        float EOF_{0}(lv_DBSL0, lat_0, lon_0) ;\n",
      "            EOF_{0}:type_of_statistical_processing = \"Subtracted mean\" ;\n",
      "            EOF_{0}:level_type = \"Depth below sea level (m)\" ;\n",
      "            EOF_{0}:grid_type = \"Latitude/longitude\" ;\n",
      "            EOF_{0}:_FillValue = 9999. ;\n",
      "\"\"\"\n",
      "\n",
      "# outputs a 2d array to string as one long vector (row order, so that last dimension varies fastest)\n",
      "# assumes the array is short enough to fit in one string\n",
      "def array_to_cdl_string(varname, data, mask = None):\n",
      "    outstr = \"\\t\\t\" + varname + \" = \"\n",
      "    flatview = np.reshape(data, (np.prod(data.shape), ))\n",
      "    if mask is None:\n",
      "        outstr += ', '.join(map(str, flatview.tolist())) + ' ;'\n",
      "    else:\n",
      "        flatmask = np.reshape(mask, (np.prod(mask.shape), ))\n",
      "        filtermasked = lambda (idx, val): '_' if flatmask[idx] else str(val)\n",
      "        outstr += ', '.join(map(filtermasked, enumerate(flatview.tolist()))) + ';'\n",
      "    return outstr\n",
      "\n",
      "def generate_ncdump(spatialeofs, temporaleofs, singvals, means, lats, lons, levels, mask, coldates, fnameout):\n",
      "    spatialeofspecifications = \"\"\n",
      "    numeofs = spatialeofs.shape[0]\n",
      "    numdates = temporaleofs.shape[1]\n",
      "    for eofidx in range(spatialeofs.shape[0]):\n",
      "        spatialeofspecifications += spatial_eof_variable_specification_template.format(eofidx)\n",
      "    datestrings = ', '.join(map(lambda date: '\"' + date + '\"', coldates))\n",
      "    \n",
      "    with open(fnameout, \"w\") as fout:\n",
      "        fout.write(eofs_ncdump_template_header.format(fnameout, numeofs, numdates, spatialeofspecifications, time.strftime('%c')))\n",
      "        fout.write(array_to_cdl_string('singvals', singvals) + '\\n')\n",
      "        fout.write(array_to_cdl_string('lv_DBSL0', levels) + '\\n')\n",
      "        fout.write(array_to_cdl_string('lat_0', lats) + '\\n')\n",
      "        fout.write(array_to_cdl_string('lon_0', lons) + '\\n')\n",
      "        fout.write(array_to_cdl_string('temporalEOFs', temporaleofs) + '\\n')\n",
      "        fout.write('\\t\\tcoldates = ' + datestrings + ';\\n' )\n",
      "        fout.write(array_to_cdl_string('meanTemps', means, mask) + '\\n')\n",
      "        for eofidx in range(numeofs):\n",
      "            fout.write(array_to_cdl_string('EOF_{0}'.format(eofidx), spatialeofs[eofidx, :], mask) + '\\n')\n",
      "        fout.write('}')\n",
      "\n",
      "generate_ncdump(spatialeofs, temporaleofs, singvals, means, lats, lons, \\\n",
      "                levels, mask, coldates, '/home/ubuntu/large-scale-climate/data/CFSR-eofs.txt')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Doesn't work because Spark?\n",
      "#cmdstr = \"/usr/local/netcdf-4/bin/ncgen -o /home/ubuntu/large-scale-climate/data/CFSR-eofs.nc \" + \\\n",
      "#         \"/home/ubuntu/large-scale-climate/data/CFSR-eofs.txt\"\n",
      "#subprocess.check_call(cmdstr, shell=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}